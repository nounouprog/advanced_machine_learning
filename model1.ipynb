{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf939e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "from sksurv.util import Surv\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from lifelines import CoxPHFitter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "df_ready_train_long = df_ready_train\n",
    "df_ready_test_long  = df_ready_test\n",
    "\n",
    "N_RUNS     = 5\n",
    "BEST_SCORE = -np.inf\n",
    "BEST_PATH  = \"\"\n",
    "TAU = 7\n",
    "\n",
    "def zscore_fit_transform(train_scores, test_scores):\n",
    "    mu = train_scores.mean()\n",
    "    sd = train_scores.std()\n",
    "    if sd <= 1e-12:\n",
    "        sd = 1.0\n",
    "    return (train_scores - mu) / sd, (test_scores - mu) / sd\n",
    "\n",
    "for i in range(1, N_RUNS + 1):\n",
    "    print(f\"\\n====== RUN {i} ======\\n\")\n",
    "\n",
    "    def is_binary(s):\n",
    "        return set(s.dropna().unique()) <= {0, 1, '0', '1', True, False}\n",
    "\n",
    "    def encode(df):\n",
    "        df = df.copy()\n",
    "        for col in [c for c in df.select_dtypes(['object', 'bool']).columns if c != 'ID']:\n",
    "            if is_binary(df[col]):\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype('int8')\n",
    "            else:\n",
    "                df[col] = df[col].astype('category').cat.codes.replace(-1, 0).astype('int16')\n",
    "        return df\n",
    "\n",
    "    train_long = encode(df_ready_train_long.copy())\n",
    "    test_long  = encode(df_ready_test_long.copy())\n",
    "\n",
    "    train_long = train_long.replace([np.inf, -np.inf], np.nan) \\\n",
    "                           .dropna(subset=['OS_YEARS', 'OS_STATUS'])\n",
    "\n",
    "    meta     = ['ID', 'OS_YEARS', 'OS_STATUS']\n",
    "    features = [c for c in train_long.columns if c not in meta]\n",
    "\n",
    "    for col in features:\n",
    "        if col not in test_long.columns:\n",
    "            test_long[col] = 0\n",
    "\n",
    "    for df in (train_long, test_long):\n",
    "        df[features] = df[features].apply(pd.to_numeric, errors='coerce') \\\n",
    "                                   .replace([np.inf, -np.inf], np.nan) \\\n",
    "                                   .fillna(0).astype(float)\n",
    "\n",
    "    features = [c for c in features if train_long[c].var() > 1e-4]\n",
    "\n",
    "    corr = train_long[features].corr().abs()\n",
    "    mask = np.triu(np.ones_like(corr, bool), k=1)\n",
    "    pairs = corr.where(mask).stack().loc[lambda s: s > .8]\n",
    "\n",
    "    drop = set()\n",
    "    mc   = corr.mean()\n",
    "    for f1, f2, _ in pairs.reset_index().values:\n",
    "        if f1 not in drop and f2 not in drop:\n",
    "            drop.add(f1 if mc[f1] > mc[f2] else f2)\n",
    "    features = [c for c in features if c not in drop]\n",
    "\n",
    "    sel, cph = [], CoxPHFitter()\n",
    "    for col in features:\n",
    "        tmp = train_long[[col, 'OS_YEARS', 'OS_STATUS']] \\\n",
    "              .rename(columns={'OS_YEARS': 'T', 'OS_STATUS': 'E'})\n",
    "        try:\n",
    "            cph.fit(tmp, 'T', 'E', show_progress=False)\n",
    "            if cph.summary.loc[col, 'p'] < .05:\n",
    "                sel.append(col)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print(f\"{len(sel)} features kept\")\n",
    "\n",
    "    X_raw_tr = train_long[sel].clip(train_long[sel].quantile(0.01),\n",
    "                                    train_long[sel].quantile(0.99), axis=1)\n",
    "    X_raw_te = test_long[sel].clip(train_long[sel].quantile(0.01),\n",
    "                                   train_long[sel].quantile(0.99), axis=1)\n",
    "\n",
    "    scaler  = StandardScaler().fit(X_raw_tr)\n",
    "    X_train = scaler.transform(X_raw_tr)\n",
    "    X_test  = scaler.transform(X_raw_te)\n",
    "\n",
    "    y_time   = train_long['OS_YEARS'].astype(float).values\n",
    "    y_event  = train_long['OS_STATUS'].astype(int).values\n",
    "    surv_all = Surv.from_arrays(event=y_event, time=y_time)\n",
    "\n",
    "    rng = np.random.default_rng(42 + i)\n",
    "\n",
    "    def relu(x): return np.maximum(x, 0.0)\n",
    "    def drelu(x): return (x > 0).astype(x.dtype)\n",
    "\n",
    "    D_in = X_train.shape[1]\n",
    "    H1, H2 = 64, 32\n",
    "\n",
    "    W1 = rng.normal(0, np.sqrt(2.0/D_in), size=(D_in, H1)); b1 = np.zeros(H1)\n",
    "    W2 = rng.normal(0, np.sqrt(2.0/H1 ), size=(H1 , H2));  b2 = np.zeros(H2)\n",
    "    Wo = rng.normal(0, np.sqrt(2.0/H2 ), size=(H2 , 1 ));  bo = np.zeros(1)\n",
    "\n",
    "    def zeros_like(x): return np.zeros_like(x)\n",
    "    mW1, vW1 = zeros_like(W1), zeros_like(W1)\n",
    "    mW2, vW2 = zeros_like(W2), zeros_like(W2)\n",
    "    mWo, vWo = zeros_like(Wo), zeros_like(Wo)\n",
    "    mb1, vb1 = zeros_like(b1), zeros_like(b1)\n",
    "    mb2, vb2 = zeros_like(b2), zeros_like(b2)\n",
    "    mbo, vbo = zeros_like(bo), zeros_like(bo)\n",
    "\n",
    "    lr = 1e-3\n",
    "    beta1, beta2, eps = 0.9, 0.999, 1e-8\n",
    "    lam = 1e-4\n",
    "\n",
    "    order = np.argsort(-y_time)\n",
    "    invord = np.empty_like(order); invord[order] = np.arange(len(order))\n",
    "    e_sorted = y_event[order].astype(float)\n",
    "\n",
    "    def cox_negloglik_and_grad_r(r):\n",
    "        r_s = r[order]\n",
    "        r_s -= r_s.max()\n",
    "        exp_r = np.exp(r_s)\n",
    "        S = np.cumsum(exp_r[::-1])[::-1]\n",
    "        loss = np.log(S[e_sorted == 1]).sum() - r_s[e_sorted == 1].sum()\n",
    "        inv_S = np.zeros_like(S)\n",
    "        inv_S[e_sorted == 1] = 1.0 / S[e_sorted == 1]\n",
    "        grad = exp_r * np.cumsum(inv_S) - e_sorted\n",
    "        return loss, grad[invord]\n",
    "\n",
    "    def forward(X):\n",
    "        a1 = relu(X @ W1 + b1)\n",
    "        a2 = relu(a1 @ W2 + b2)\n",
    "        r  = (a2 @ Wo + bo).ravel()\n",
    "        return r, (X, a1, a2)\n",
    "\n",
    "    def backward(cache, grad_r):\n",
    "        X, a1, a2 = cache\n",
    "        gWo = a2.T @ grad_r[:, None] + lam * Wo\n",
    "        gbo = grad_r.sum()\n",
    "        ga2 = grad_r[:, None] @ Wo.T\n",
    "        gz2 = ga2 * (a2 > 0)\n",
    "        gW2 = a1.T @ gz2 + lam * W2\n",
    "        gb2 = gz2.sum(axis=0)\n",
    "        ga1 = gz2 @ W2.T\n",
    "        gz1 = ga1 * (a1 > 0)\n",
    "        gW1 = X.T @ gz1 + lam * W1\n",
    "        gb1 = gz1.sum(axis=0)\n",
    "        return gW1, gb1, gW2, gb2, gWo, gbo\n",
    "\n",
    "    def adam_update(W, gW, mW, vW, t):\n",
    "        mW = beta1*mW + (1-beta1)*gW\n",
    "        vW = beta2*vW + (1-beta2)*(gW*gW)\n",
    "        W -= lr * (mW / (1-beta1**t)) / (np.sqrt(vW / (1-beta2**t)) + eps)\n",
    "        return W, mW, vW\n",
    "\n",
    "    EPOCHS = 140\n",
    "    best_loss, bad, t_adam = np.inf, 0, 0\n",
    "\n",
    "    for _ in range(EPOCHS):\n",
    "        r, cache = forward(X_train)\n",
    "        loss, grad_r = cox_negloglik_and_grad_r(r)\n",
    "        t_adam += 1\n",
    "\n",
    "        gW1, gb1, gW2, gb2, gWo, gbo = backward(cache, grad_r)\n",
    "        W1, mW1, vW1 = adam_update(W1, gW1, mW1, vW1, t_adam)\n",
    "        W2, mW2, vW2 = adam_update(W2, gW2, mW2, vW2, t_adam)\n",
    "        Wo, mWo, vWo = adam_update(Wo, gWo, mWo, vWo, t_adam)\n",
    "        b1, mb1, vb1 = adam_update(b1, gb1, mb1, vb1, t_adam)\n",
    "        b2, mb2, vb2 = adam_update(b2, gb2, mb2, vb2, t_adam)\n",
    "        bo, mbo, vbo = adam_update(bo, gbo, mbo, vbo, t_adam)\n",
    "\n",
    "        if loss < best_loss - 1e-4:\n",
    "            best_loss, bad = loss, 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= 20:\n",
    "                break\n",
    "\n",
    "    risk_tr_dl = forward(X_train)[0]\n",
    "    risk_te_dl = forward(X_test)[0]\n",
    "\n",
    "    # CoxNet on top of DL score\n",
    "    risk_tr_z, risk_te_z = zscore_fit_transform(risk_tr_dl, risk_te_dl)\n",
    "    X_train_aug = np.column_stack([X_train, risk_tr_z])\n",
    "    X_test_aug  = np.column_stack([X_test,  risk_te_z])\n",
    "\n",
    "    alpha_grid = np.logspace(-2, 0, 30)\n",
    "    l1_grid    = np.linspace(0.001, 0.1, 35)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123+i)\n",
    "\n",
    "    best_a = best_l1 = None\n",
    "    best_c = -np.inf\n",
    "\n",
    "    for l1 in l1_grid:\n",
    "        for a in alpha_grid:\n",
    "            scores = []\n",
    "            model = CoxnetSurvivalAnalysis(alphas=[a], l1_ratio=l1, max_iter=100_000)\n",
    "            for tr, va in cv.split(X_train_aug, y_event):\n",
    "                model.fit(X_train_aug[tr], surv_all[tr])\n",
    "                risk = model.predict(X_train_aug[va])\n",
    "                scores.append(concordance_index_ipcw(surv_all[tr], surv_all[va], risk, tau=TAU)[0])\n",
    "            if np.mean(scores) > best_c:\n",
    "                best_c, best_a, best_l1 = np.mean(scores), a, l1\n",
    "\n",
    "    enet = CoxnetSurvivalAnalysis(alphas=[best_a], l1_ratio=best_l1, max_iter=100_000)\n",
    "    enet.fit(X_train_aug, surv_all)\n",
    "\n",
    "    risk_tr_final = enet.predict(X_train_aug)\n",
    "    risk_te_final = enet.predict(X_test_aug)\n",
    "\n",
    "    test_long['risk_row'] = risk_te_final\n",
    "\n",
    "    submission = test_long.groupby('ID', as_index=False).agg(risk_score=('risk_row', 'mean'))\n",
    "    submission['risk_score'] = (submission['risk_score'] - submission['risk_score'].min()) / \\\n",
    "                               (submission['risk_score'].max() - submission['risk_score'].min())\n",
    "\n",
    "    score = concordance_index_ipcw(surv_all, surv_all, risk_tr_final, tau=TAU)[0]\n",
    "    print(f\" Train C-index @7y = {score:.5f}\")\n",
    "\n",
    "    out_path = f\"submission_run_{i}_score_{score:.5f}.csv\"\n",
    "    submission.to_csv(out_path, index=False)\n",
    "\n",
    "    if score > BEST_SCORE:\n",
    "        BEST_SCORE, BEST_PATH = score, out_path\n",
    "\n",
    "print(f\"\\nBEST SCORE : {BEST_SCORE:.5f}\")\n",
    "print(f\"SUBMISSION : {BEST_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
